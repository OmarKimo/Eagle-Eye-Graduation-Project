{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "MhpMxopeGYu1",
    "outputId": "ea0b8ae8-89a5-44de-f654-868aa0bc49bd"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AegYQg_01vk6"
   },
   "outputs": [],
   "source": [
    "#!rm -r -d \"/content/drive/My Drive/GP/dstl/4_bands_10_classes_5000_Patches/data\"\n",
    "!rm -r -d msk\n",
    "!rm -r -d weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4p7D89j7xwNw"
   },
   "outputs": [],
   "source": [
    "!mkdir -p msk weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "9T-cByXjjAr0",
    "outputId": "b8e661e7-b6dd-4ced-e0fe-d4d9ec98d453",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "-XbfkU7BeziQ",
    "outputId": "caead43a-eafe-46f9-c65b-05180489698e"
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.wkt import loads\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "from matplotlib.patches import Polygon\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import re\n",
    "import zipfile\n",
    "!pip install tifffile\n",
    "import tifffile as tiff\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "K.set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MIih5qt7t9SM"
   },
   "outputs": [],
   "source": [
    "bands_choices = [3,4,20]\n",
    "chosen_bands = bands_choices[2]\n",
    "\n",
    "patches_choices = [2500, 5000]\n",
    "chosen_patches = patches_choices[1]\n",
    "\n",
    "case_choices = [\"esri\", \"\"]\n",
    "chosen_case = case_choices[1]\n",
    "\n",
    "path_choices = [f\"/content/drive/My Drive/GP/dstl/{chosen_bands}_bands_10_classes_{chosen_patches}_Patches/\", \n",
    "                f\"/content/drive/My Drive/GP/dstl/trial/{chosen_bands}_bands_10_classes_{chosen_patches}_Patches/\"\n",
    "                ]\n",
    "chosen_path = path_choices[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tY9wZUOibOOu"
   },
   "outputs": [],
   "source": [
    "if chosen_path == path_choices[1]:\n",
    "    if os.path.exists(chosen_path) and os.path.isdir(chosen_path):\n",
    "        shutil.rmtree(chosen_path)\n",
    "        !mkdir -p msk weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T20:10:43.394643Z",
     "start_time": "2019-12-12T20:10:43.389653Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "2VkQkmyUz9Nx"
   },
   "outputs": [],
   "source": [
    "trainWKT = pd.read_csv('/content/drive/My Drive/GP/dstl/train_wkt_v4.csv') \n",
    "gridSizes = pd.read_csv('/content/drive/My Drive/GP/dstl/grid_sizes.csv', names=['ImageId', 'Xmax', 'Ymin'], skiprows=1)\n",
    "\n",
    "#Convert all image coordinates\n",
    "def ConvertCoord(Coords, Size, XYcoords):\n",
    "    Xmax, Ymin = XYcoords\n",
    "    Height, Width=Size\n",
    "    Width = 1.0 * Width * Width / (Width + 1)\n",
    "    Height = 1.0 * Height * Height / (Height + 1)\n",
    "    Xfinal , Yfinal = Width / Xmax , Height / Ymin\n",
    "    Coords[:, 0] *= Xfinal\n",
    "    Coords[:, 1] *= Yfinal\n",
    "    IntCoords = np.round(Coords).astype(np.int32)\n",
    "    return IntCoords\n",
    "\n",
    "#Find maximum coordinates for x and minimun coordinates for y\n",
    "def GetXY(GridSizes, ImageId):\n",
    "    Xmax, Ymin = GridSizes[GridSizes.ImageId == ImageId].iloc[0, 1:].astype(float)\n",
    "    return (Xmax, Ymin)\n",
    "\n",
    "#Find polygon list for class for image\n",
    "def GetPolygonsList(wkt_list, ImageId, classType):\n",
    "    Allpolygon = wkt_list[wkt_list.ImageId == ImageId]\n",
    "    multipolygon = Allpolygon[Allpolygon.ClassType == classType].MultipolygonWKT\n",
    "    polygonList = None\n",
    "    if len(multipolygon) != 0:\n",
    "        polygonList = loads(multipolygon.values[0])\n",
    "    return polygonList\n",
    "\n",
    "def GetTheConvertedContours(PolygonList, Size, XYCoods):\n",
    "    if PolygonList is None:\n",
    "        return None\n",
    "    if Size is None or Size[0] <= 0 or Size[1] <= 0:\n",
    "        return None\n",
    "    ExteriorList,InteriorList = [],[]\n",
    "    for Polygon in PolygonList:\n",
    "        ExteriorList.append(    ConvertCoord( np.array(list(Polygon.exterior.coords)) , Size, XYCoods)  )\n",
    "        for j in Polygon.interiors:\n",
    "            InteriorList.append(ConvertCoord(np.array(list(j.coords)), Size, XYCoods))\n",
    "    return ExteriorList, InteriorList\n",
    "\n",
    "def PlotMask(Size, Contours):\n",
    "    if Size is None:\n",
    "        return None\n",
    "    if Size[0] <= 0 or Size[1] <= 0:\n",
    "        return None\n",
    "    mask = np.zeros(Size, np.uint8)\n",
    "    if Contours is None:\n",
    "        return mask\n",
    "    ExteriorList, InteriorList = Contours\n",
    "    cv2.fillPoly(mask, ExteriorList, 1)\n",
    "    cv2.fillPoly(mask, InteriorList, 0)\n",
    "    return mask\n",
    "\n",
    "#Fill polygons exterior and interior points and return mask of images\n",
    "def GenerateMaskForImage(img_size, imageId, class_type, GridSizes=gridSizes, wktList=trainWKT):\n",
    "    XY = GetXY(GridSizes, imageId)\n",
    "    PolygonList = GetPolygonsList(wktList, imageId, class_type)\n",
    "    contours = GetTheConvertedContours(PolygonList, img_size, XY)\n",
    "    Mask = PlotMask(img_size, contours)\n",
    "    return Mask\n",
    "\n",
    "\n",
    "def ContrastAdjustment(img, low_p = 5, high_p = 95):\n",
    "    img_adjusted = np.zeros_like(img, dtype=np.float32)\n",
    "    for i in range(img.shape[2]):\n",
    "        mn, mx = 0, 1       # np.min(img), np.max(img)\n",
    "        p_low, p_high = np.percentile(img[:, :, i], low_p), np.percentile(img[:, :, i], high_p)\n",
    "        tmp = mn + (img[:, :, i] - p_low) * (mx - mn) / (p_high - p_low)\n",
    "        tmp[tmp < mn] = mn\n",
    "        tmp[tmp > mx] = mx\n",
    "        img_adjusted[:, :, i] = tmp\n",
    "    return img_adjusted.astype(np.float32)\n",
    "    \n",
    "def ReadTif(image_id, bands=chosen_bands, size=800, case=chosen_case):\n",
    "    if bands == 3:\n",
    "        if case == \"esri\":\n",
    "            dir = \"/content/drive/My Drive/GP/Raster/\"\n",
    "            pattern = r'*.tif'\n",
    "            gen = glob.iglob(os.path.join(dir, pattern))\n",
    "            filename = next(gen)\n",
    "            img_4 = tiff.imread(filename)\n",
    "            img = np.zeros((3000, 3000, bands), \"float32\")\n",
    "            img = img_4[ 1500:2500 , 5000:6000 , 0:3]\n",
    "            #img = np.rollaxis(img, 0, 3)\n",
    "            img = cv2.resize(img, (size, size))\n",
    "        else:\n",
    "            filename = \"/content/drive/My Drive/GP/dstl/three_band/{}.tif\".format(image_id)\n",
    "            img = tiff.imread(filename)\n",
    "            img = np.rollaxis(img, 0, 3)\n",
    "            img = cv2.resize(img, (size, size))\n",
    "\n",
    "    elif bands == 4:\n",
    "        if case == 'esri':\n",
    "            dir = \"/content/drive/My Drive/GP/Raster/\"\n",
    "            pattern = r'*.tif'\n",
    "            gen = glob.iglob(os.path.join(dir, pattern))\n",
    "            filename = next(gen)\n",
    "            img = tiff.imread(filename)\n",
    "            #img = cv2.resize(img, (size, size))\n",
    "        else:\n",
    "            # for type M \n",
    "            img_M = np.transpose(tiff.imread(\"/content/drive/My Drive/GP/dstl/sixteen_band/{}_M.tif\".format(image_id)), (1,2,0))\n",
    "            img_M = cv2.resize(img_M, (size, size))\n",
    "\n",
    "            # for RGB \n",
    "            img_RGB = tiff.imread(\"/content/drive/My Drive/GP/dstl/three_band/{}.tif\".format(image_id))\n",
    "            img_RGB = np.rollaxis(img_RGB, 0, 3)\n",
    "            img_RGB = cv2.resize(img_RGB, (size, size))\n",
    "\n",
    "            img = np.zeros((img_RGB.shape[0], img_RGB.shape[1], bands), \"float32\")\n",
    "            #print(f'RGB shape: {img_RGB.shape}\\nM shape: {img_M.shape}\\nimg shape: {img.shape}')\n",
    "            img[..., 0:3] = img_RGB\n",
    "            img[..., 3] = img_M[ : , : , 7]\n",
    "        \n",
    "    elif bands==20:\n",
    "        # for type M \n",
    "        img_M = np.transpose(tiff.imread(\"/content/drive/My Drive/GP/dstl/sixteen_band/{}_M.tif\".format(image_id)), (1,2,0))\n",
    "        img_M = cv2.resize(img_M, (size, size))\n",
    "        # for type A\n",
    "        img_A = np.transpose(tiff.imread(\"/content/drive/My Drive/GP/dstl/sixteen_band/{}_A.tif\".format(image_id)), (1,2,0))\n",
    "        img_A = cv2.resize(img_A, (size, size))\n",
    "        # for type P\n",
    "        img_P = tiff.imread(\"/content/drive/My Drive/GP/dstl/sixteen_band/{}_P.tif\".format(image_id))\n",
    "        img_P = cv2.resize(img_P, (size, size))\n",
    "\n",
    "        filename = \"/content/drive/My Drive/GP/dstl/three_band/{}.tif\".format(image_id)\n",
    "        # for RGB \n",
    "        img_RGB = tiff.imread(filename)\n",
    "        img_RGB = np.rollaxis(img_RGB, 0, 3)\n",
    "        img_RGB = cv2.resize(img_RGB, (size, size))\n",
    "\n",
    "        img = np.zeros((img_RGB.shape[0], img_RGB.shape[1], bands), \"float32\")\n",
    "        img[..., 0:3] = img_RGB\n",
    "        img[..., 3] = img_P\n",
    "        img[..., 4:12] = img_M\n",
    "        img[..., 12:21] = img_A\n",
    "\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T20:11:48.683127Z",
     "start_time": "2019-12-12T20:11:48.674135Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "YO27qAkqz9Oi"
   },
   "outputs": [],
   "source": [
    "num_classes = 10 # total number of class\n",
    "\n",
    "def StartTrain():\n",
    "    #put all image into one image\n",
    "    Size = 800\n",
    "    x = np.zeros((5 * Size, 5 * Size, chosen_bands)) #input for Unet\n",
    "    y = np.zeros((5 * Size, 5 * Size, num_classes)) # exp output\n",
    "    ids = sorted(trainWKT.ImageId.unique())\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            id = ids[5 * i + j]\n",
    "            img = ReadTif(id)\n",
    "            img = ContrastAdjustment(img)\n",
    "            Xi,Yi=Size * i,Size * j\n",
    "            x[Xi : Xi + Size, Yi : Yi + Size, :] = img[:Size, :Size,:]\n",
    "            for Cls in range(num_classes):\n",
    "                y[Xi:Xi + Size, Yi : Yi + Size, Cls] = GenerateMaskForImage((img.shape[0], img.shape[1]),id, Cls + 1) #[:Size, :Size]\n",
    "    np.save((chosen_path+'data/x_trn_%d') % num_classes, x)\n",
    "    np.save((chosen_path+'data/y_trn_%d') % num_classes, y)\n",
    "\n",
    "\n",
    "def generateSamples(img, msk, amt=chosen_patches, aug=True):\n",
    "    xm, ym = img.shape[0] - InputLayerSize, img.shape[1] - InputLayerSize\n",
    "    x, y = [], []\n",
    "    bestThreshold = [0.4, 0.1, 0.1, 0.15, 0.3, 0.95, 0.1, 0.05, 0.001, 0.005]     # from trial and error \n",
    "    for i in range(amt):\n",
    "        x_random = random.randint(0, xm)\n",
    "        y_random = random.randint(0, ym)\n",
    "        img_random = img[x_random:x_random + InputLayerSize, y_random:y_random + InputLayerSize]        # random image\n",
    "        msk_random = msk[x_random:x_random + InputLayerSize, y_random:y_random + InputLayerSize]        # random mask \n",
    "        for j in range(num_classes):\n",
    "            if 1.0 * np.sum(msk_random[:, :, j]) / InputLayerSize ** 2 > bestThreshold[j]:\n",
    "                if random.uniform(0, 1) > 0.5:\n",
    "                    img_random = img_random[::-1]\n",
    "                    msk_random = msk_random[::-1]\n",
    "                if random.uniform(0, 1) > 0.5:\n",
    "                    img_random = img_random[:, ::-1]\n",
    "                    msk_random = msk_random[:, ::-1]\n",
    "                x.append(img_random)\n",
    "                y.append(msk_random)\n",
    "    x, y = 2 * np.transpose(x, (0, 3, 1, 2)) - 1, np.transpose(y, (0, 3, 1, 2))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sn3ztTCNz9Ot"
   },
   "source": [
    "## Split train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T20:12:18.245686Z",
     "start_time": "2019-12-12T20:12:18.238690Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "l9N-MOOjz9Ou"
   },
   "outputs": [],
   "source": [
    "def pickValidation():\n",
    "    # pick samples for validatio\n",
    "    img = np.load((chosen_path+'data/x_trn_%d.npy') % num_classes)\n",
    "    msk = np.load((chosen_path+'data/y_trn_%d.npy') % num_classes)\n",
    "    \n",
    "    x, y = generateSamples(img, msk, amt=1500)\n",
    "\n",
    "    np.save((chosen_path+'data/x_tmp_%d') % num_classes, x)\n",
    "    np.save((chosen_path+'data/y_tmp_%d') % num_classes, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T20:12:26.955186Z",
     "start_time": "2019-12-12T20:12:26.941214Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "hVkjr1Wjz9O0"
   },
   "outputs": [],
   "source": [
    "InputLayerSize = 160\n",
    "\n",
    "def conv_block(n_neuron, input):\n",
    "    return Conv2D(n_neuron, 3, activation='relu', padding='same')(input)\n",
    "\n",
    "def maxPool_block(input):\n",
    "    return MaxPooling2D(pool_size=(2, 2))(input)\n",
    "\n",
    "def upSample_block(input1, input2):\n",
    "    return concatenate([UpSampling2D(size=(2, 2))(input1), input2], axis=1)\n",
    "\n",
    "def buildModel(nStart_neuron = 32):\n",
    "    input_layer = Input((chosen_bands, InputLayerSize, InputLayerSize))\n",
    "\n",
    "    # Contracting Path [Down Sampling]\n",
    "\n",
    "    conv1_1 = conv_block(nStart_neuron, input_layer)\n",
    "    conv1_2 = conv_block(nStart_neuron, conv1_1)\n",
    "    max_pool1 = maxPool_block(conv1_2)\n",
    "\n",
    "    conv2_1 = conv_block(nStart_neuron * 2, max_pool1)\n",
    "    conv2_2 = conv_block(nStart_neuron * 2, conv2_1)\n",
    "    max_pool2 = maxPool_block(conv2_2)\n",
    "\n",
    "    conv3_1 = conv_block(nStart_neuron * 4, max_pool2)\n",
    "    conv3_2 = conv_block(nStart_neuron * 4, conv3_1)\n",
    "    max_pool3 = maxPool_block(conv3_2)\n",
    "\n",
    "    conv4_1 = conv_block(nStart_neuron* 8, max_pool3)\n",
    "    conv4_2 = conv_block(nStart_neuron* 8, conv4_1)\n",
    "    max_pool4 = maxPool_block(conv4_2)\n",
    "\n",
    "    conv5_1 = conv_block(nStart_neuron * 16, max_pool4)\n",
    "    conv5_2 = conv_block(nStart_neuron * 16, conv5_1)\n",
    "\n",
    "    # Expansive Path [Up Sampling]\n",
    "\n",
    "    up_sample6 = upSample_block(conv5_2, conv4_2)\n",
    "    conv6_1 = conv_block(nStart_neuron * 8, up_sample6)\n",
    "    conv6_2 = conv_block(nStart_neuron * 8, conv6_1)\n",
    "\n",
    "    up_sample7 = upSample_block(conv6_2, conv3_2)\n",
    "    conv7_1 = conv_block(nStart_neuron * 4, up_sample7)\n",
    "    conv7_2 = conv_block(nStart_neuron * 4, conv7_1)\n",
    "\n",
    "    up_sample8 = upSample_block(conv7_2, conv2_2)\n",
    "    conv8_1 = conv_block(nStart_neuron * 2, up_sample8)\n",
    "    conv8_2 = conv_block(nStart_neuron * 2, conv8_1)\n",
    "\n",
    "    up_sample9 = upSample_block(conv8_2, conv1_2)\n",
    "    conv9_1 = conv_block(nStart_neuron, up_sample9)\n",
    "    conv9_2 = conv_block(nStart_neuron, conv9_1)\n",
    "\n",
    "    finalConv = Conv2D(num_classes, 1, activation='sigmoid')(conv9_2)\n",
    "\n",
    "    model = Model(input=input_layer, output=finalConv)\n",
    "    model.compile(optimizer = Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T20:35:34.197961Z",
     "start_time": "2019-12-08T20:35:33.204003Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "zRvdplzmz9O3",
    "outputId": "5fed5651-d1e9-4975-f81e-5670d3c37695"
   },
   "outputs": [],
   "source": [
    "model = buildModel()\n",
    "print(chosen_path)\n",
    "if os.path.isfile(f\"{chosen_path}unet_{chosen_bands}_10_jk_BestScore\"):\n",
    "    model.load_weights(f\"{chosen_path}unet_{chosen_bands}_10_jk_BestScore\")\n",
    "    print(\"weights loaded ......\")\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T20:39:30.968702Z",
     "start_time": "2019-12-08T20:39:25.490222Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "-7hlKPYSz9O5"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import pydot\n",
    "from keras.utils import plot_model\n",
    "import pydotplus\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "keras.utils.vis_utils.pydot = pydot\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KHa7qysHf_Nn"
   },
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, show_layer_names=True, to_file='model.png')\n",
    "Image(retina=True, filename='model.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T11:56:48.025856Z",
     "start_time": "2019-12-09T11:56:47.862948Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "TjVfc0Ebz9O_"
   },
   "outputs": [],
   "source": [
    "def jaccard_similarity_score(Y1, Y2):\n",
    "    Y = Y1 == Y2\n",
    "    return np.count_nonzero(Y) / Y.size\n",
    "\n",
    "def calcAccuracy(model):\n",
    "    img = np.load((chosen_path+'data/x_tmp_%d.npy') % num_classes)\n",
    "    msk = np.load((chosen_path+'data/y_tmp_%d.npy') % num_classes)\n",
    "\n",
    "    prd = model.predict(img, batch_size=4)\n",
    "    sumValues, thresholds = [], []\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        mskTrain, prdTrain = msk[:, i, :, :], prd[:, i, :, :]\n",
    "        mskTrain = mskTrain.reshape(msk.shape[0] * msk.shape[2], msk.shape[3])\n",
    "        prdTrain = prdTrain.reshape(msk.shape[0] * msk.shape[2], msk.shape[3])\n",
    "        mx, threshold = 0, 0\n",
    "        for j in range(10):\n",
    "            score = jaccard_similarity_score(mskTrain, prdTrain > j / 10.0)      \n",
    "            if score > mx:\n",
    "                mx = score\n",
    "                threshold = j / 10.0\n",
    "        sumValues.append(mx)\n",
    "        thresholds.append(threshold)\n",
    "\n",
    "    accuracy = sum(sumValues) / 10.0\n",
    "    return accuracy, thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T20:12:45.721307Z",
     "start_time": "2019-12-12T20:12:45.711311Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "xY3JdS3sz9PQ"
   },
   "outputs": [],
   "source": [
    "def trainModel():\n",
    "    xValidate, yValidate = np.load((chosen_path+'data/x_tmp_%d.npy') % num_classes), np.load((chosen_path+'data/y_tmp_%d.npy') % num_classes)    # load validate data\n",
    "    imgTrained = np.load((chosen_path+'data/x_trn_%d.npy') % num_classes)\n",
    "    mskTrained = np.load((chosen_path+'data/y_trn_%d.npy') % num_classes)\n",
    "  \n",
    "    model_checkpoint = ModelCheckpoint('weights/unet_tmp.hdf5', monitor='loss', save_best_only=True)   \n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir='./logs')        \n",
    "    arr = []\n",
    "    for _ in range(2):\n",
    "        xTrain, yTrain = generateSamples(imgTrained, mskTrained) \n",
    "        model.fit(xTrain, yTrain, batch_size=64, nb_epoch=5, verbose=1, shuffle=True,\n",
    "                  callbacks=[model_checkpoint,tensorboard_callback], validation_data=(xValidate, yValidate))       \n",
    "        del x_trn\n",
    "        del y_trn\n",
    "        accuracy, thresholds = calcAccuracy(model)\n",
    "        arr.append(float(\"{:.4f}\".format(accuracy)))\n",
    "        model.save_weights((f'{chosen_path}unet_{chosen_bands}_10_jk%.4f') % accuracy)\n",
    "    arr.sort()\n",
    "    os.rename(f'{chosen_path}unet_{chosen_bands}_10_jk{arr[-1]}', f'{chosen_path}unet_{chosen_bands}_10_jk_BestScore')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T13:11:02.694052Z",
     "start_time": "2019-12-09T13:11:02.652075Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "NoEwTPs8z9PS"
   },
   "outputs": [],
   "source": [
    "if chosen_path == path_choices[1]: StartTrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9AsvLByLz9PU"
   },
   "outputs": [],
   "source": [
    "if chosen_path == path_choices[1]: pickValidation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AOTBm8x0KoHX"
   },
   "outputs": [],
   "source": [
    "if chosen_path == path_choices[1]: model = trainModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U_KKdf66z9PZ"
   },
   "outputs": [],
   "source": [
    "accuracy, thresholds = calcAccuracy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ll1067xueMWJ"
   },
   "outputs": [],
   "source": [
    "chosen_bands = 3\n",
    "chosen_patches = 5000\n",
    "chosen_path = f\"/content/drive/My Drive/GP/dstl/{chosen_bands}_bands_10_classes_{chosen_patches}_Patches/\"\n",
    "\n",
    "model = buildModel()\n",
    "model.load_weights(f'{chosen_path}unet_{chosen_bands}_10_jk_BestScore')\n",
    "accuracy, thresholds = calcAccuracy(model)\n",
    "print(accuracy)\n",
    "print(thresholds)\n",
    "np.save(f'{chosen_path}unet_{chosen_bands}_thresholds', thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hbw86sFVeXe_"
   },
   "outputs": [],
   "source": [
    "chosen_bands = 4\n",
    "chosen_patches = 5000\n",
    "chosen_path = f\"/content/drive/My Drive/GP/dstl/{chosen_bands}_bands_10_classes_{chosen_patches}_Patches/\"\n",
    "\n",
    "model = buildModel()\n",
    "model.load_weights(f'{chosen_path}unet_{chosen_bands}_10_jk_BestScore')\n",
    "accuracy, thresholds = calcAccuracy(model)\n",
    "print(accuracy)\n",
    "print(thresholds)\n",
    "np.save(f'{chosen_path}unet_{chosen_bands}_thresholds', thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hqwIVAwgeXNy"
   },
   "outputs": [],
   "source": [
    "chosen_bands = 20\n",
    "chosen_patches = 2500\n",
    "chosen_path = f\"/content/drive/My Drive/GP/dstl/{chosen_bands}_bands_10_classes_{chosen_patches}_Patches/\"\n",
    "\n",
    "model = buildModel()\n",
    "model.load_weights(f'{chosen_path}unet_{chosen_bands}_10_jk_BestScore')\n",
    "accuracy, thresholds = calcAccuracy(model)\n",
    "print(accuracy)\n",
    "print(thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qlIB1qAgeW-F"
   },
   "outputs": [],
   "source": [
    "chosen_bands = 20\n",
    "chosen_patches = 5000\n",
    "chosen_path = f\"/content/drive/My Drive/GP/dstl/{chosen_bands}_bands_10_classes_{chosen_patches}_Patches/\"\n",
    "\n",
    "model = buildModel()\n",
    "model.load_weights(f'{chosen_path}unet_{chosen_bands}_10_jk_BestScore')\n",
    "accuracy, thresholds = calcAccuracy(model)\n",
    "print(accuracy)\n",
    "print(thresholds)\n",
    "np.save(f'{chosen_path}unet_{chosen_bands}_thresholds', thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UJ0k9xxIKe33"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BC6wmNa4Ke0C"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wX_-LiG1Ken6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "UNet Training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
